{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a68ebb7-fbbf-4ff7-9c7f-56c9d10a1bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7873\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7873/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from model import Generator\n",
    "import pandas as pd\n",
    "import torchvision.utils as vutils  # Import vutils\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the function to generate and visualize images\n",
    "def generate_and_visualize(image):\n",
    "    checkpoint_dir = \"checkpoints/checkpoint.pth\"\n",
    "    G = Generator()\n",
    "    \n",
    "    if checkpoint_dir and os.path.exists(checkpoint_dir):\n",
    "        checkpoint = torch.load(checkpoint_dir, map_location=torch.device('cpu'))\n",
    "        G.load_state_dict(checkpoint['model_G_state_dict'])\n",
    "        print(\"Checkpoint loaded successfully.\")\n",
    "    else:\n",
    "        print(\"No checkpoint found. Starting from scratch.\")\n",
    "    \n",
    "    # Convert PIL image to tensor\n",
    "    transform = []\n",
    "    crop_size = 178\n",
    "    image_size = 128\n",
    "    if(image.size[0]!=178 or image.size[1]!=218):\n",
    "        transform.append(T.Resize((218, 178)))\n",
    "    transform.append(T.CenterCrop(crop_size))\n",
    "    transform.append(T.Resize(image_size))\n",
    "    transform.append(T.ToTensor())\n",
    "    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\n",
    "    transform = T.Compose(transform)\n",
    "    x_real = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    num_labels = 5  # Number of filter options (or classes)\n",
    "    all_images = []\n",
    "    generated_images = []\n",
    "\n",
    "    for k in range(num_labels):\n",
    "        # Create one-hot label for the k-th class\n",
    "        one_hot_label = torch.zeros((1, num_labels)).to(device)\n",
    "        one_hot_label[0, k] = 1\n",
    "\n",
    "        # Generate the image\n",
    "        with torch.no_grad():\n",
    "            fake_image = G(x_real[0].unsqueeze(0).to(device), one_hot_label).detach().cpu()\n",
    "        \n",
    "        generated_images.append(fake_image.squeeze(0))\n",
    "\n",
    "    normalized_images = []\n",
    "    for img in generated_images:\n",
    "        # Normalize the image (assuming each image is in the format CxHxW)\n",
    "        normalized_img = (img - img.min()) / (img.max() - img.min())\n",
    "        normalized_images.append(normalized_img)\n",
    "\n",
    "    normalized_images = [np.transpose(np.array(img), (1, 2, 0)) for img in normalized_images]\n",
    "    return normalized_images\n",
    "     \n",
    "\n",
    "desc = \"\"\"\"Upload a face image to visualize different attributes such as hair color and gender.\n",
    "Make sure the image has face zoomed and centered on it as the model is quite trivial.\n",
    "The app will generate and display five images representing different features namely- Black Hair, Blonde Hair, Brown Hair, Gender and Age.\n",
    "This app uses starGAN model for image translation which has been trained on celebFaces dataest which has around 40 facial attributes\"\n",
    "\"\"\"\n",
    "\n",
    "# Create the Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=generate_and_visualize,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Input Image\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Black Hair\"),\n",
    "        gr.Image(type=\"pil\", label=\"Blond Hair\"),\n",
    "        gr.Image(type=\"pil\", label=\"Brown Hair\"),\n",
    "        gr.Image(type=\"pil\", label=\"Male\"),\n",
    "        gr.Image(type=\"pil\", label=\"Young\")\n",
    "    ],\n",
    "    title=\"Image to Image Translation using starGAN\",\n",
    "    description=desc,\n",
    "    \n",
    "    # live=True\n",
    ")\n",
    "\n",
    "# Launch the app\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c24f16-8654-4b38-a116-fe8e25a104f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c360d9c-4564-4f05-8743-7e214279446c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
